{
    "settings": {
        "model": "STORAGE_DIR/models/custom_roberta",
        "save_path": "STORAGE_DIR/models/custom_roberta",
        "tokenizer": "STORAGE_DIR/models/backups/roberta_mlm_241019",
        "dataset":"STORAGE_DIR/datasets", 
        "task": "glue",
        "accelerate": true,
        "logging": false,
        "exp_name": "glue_finetune",
        "epochs": 3,
        "batch_size": 32, 
        "lr": 1e-5
    },
    "config": {
        "max_position_embeddings": 514,
        "hidden_size": 768,
        "num_attention_heads": 12,
        "num_hidden_layers": 6,
        "type_vocab_size": 1,
        "attn_mechanism": "eager",
        "num_labels": 2
    }
}