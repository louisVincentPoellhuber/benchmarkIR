{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lvpoellhuber/storage\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "STORAGE_DIR = os.getenv(\"STORAGE_DIR\")\n",
    "print(STORAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>computer</th>\n",
       "      <th>job_id</th>\n",
       "      <th>cola</th>\n",
       "      <th>mnli</th>\n",
       "      <th>mrpc</th>\n",
       "      <th>qnli</th>\n",
       "      <th>qqp</th>\n",
       "      <th>rte</th>\n",
       "      <th>sst2</th>\n",
       "      <th>wnli</th>\n",
       "      <th>model_path</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roberta_test</th>\n",
       "      <td>2024-12-04 16:33:02</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1433</td>\n",
       "      <td>0.696389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722285</td>\n",
       "      <td>0.533351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.479520</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.423822</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/robe...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sparse_ft</th>\n",
       "      <td>2024-12-04 16:37:23</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1435</td>\n",
       "      <td>0.637677</td>\n",
       "      <td>0.316863</td>\n",
       "      <td>0.589015</td>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.368183</td>\n",
       "      <td>0.507992</td>\n",
       "      <td>0.498737</td>\n",
       "      <td>0.561869</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/spar...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>added_loss</th>\n",
       "      <td>2024-12-04 16:38:17</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1436</td>\n",
       "      <td>0.693487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662753</td>\n",
       "      <td>0.506805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456294</td>\n",
       "      <td>0.509848</td>\n",
       "      <td>0.569024</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sparse_ft</th>\n",
       "      <td>2024-12-04 17:05:29</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1438</td>\n",
       "      <td>0.638869</td>\n",
       "      <td>0.381189</td>\n",
       "      <td>0.595644</td>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.633111</td>\n",
       "      <td>0.484765</td>\n",
       "      <td>0.498737</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/spar...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>added_loss</th>\n",
       "      <td>2024-12-04 17:05:48</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.691502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662753</td>\n",
       "      <td>0.506805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456294</td>\n",
       "      <td>0.509848</td>\n",
       "      <td>0.569024</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_2e-5</th>\n",
       "      <td>2024-12-04 17:06:03</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.691502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662753</td>\n",
       "      <td>0.503922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471778</td>\n",
       "      <td>0.508838</td>\n",
       "      <td>0.576178</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_2e-4</th>\n",
       "      <td>2024-12-04 17:06:18</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.692296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662753</td>\n",
       "      <td>0.506805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471778</td>\n",
       "      <td>0.509343</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ramp_64</th>\n",
       "      <td>2024-12-04 17:06:33</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.689913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664962</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440809</td>\n",
       "      <td>0.507828</td>\n",
       "      <td>0.576178</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ramp_16</th>\n",
       "      <td>2024-12-04 17:06:49</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.689913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.667172</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.479520</td>\n",
       "      <td>0.510354</td>\n",
       "      <td>0.561869</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_0.5</th>\n",
       "      <td>2024-12-04 17:07:04</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.815952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.856313</td>\n",
       "      <td>0.900909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632118</td>\n",
       "      <td>0.907449</td>\n",
       "      <td>0.203283</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_1</th>\n",
       "      <td>2024-12-04 17:07:19</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.812408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.855240</td>\n",
       "      <td>0.896987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625125</td>\n",
       "      <td>0.920581</td>\n",
       "      <td>0.554714</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_5</th>\n",
       "      <td>2024-12-04 17:07:34</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.808071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.667172</td>\n",
       "      <td>0.495117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528222</td>\n",
       "      <td>0.510354</td>\n",
       "      <td>0.423822</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_10</th>\n",
       "      <td>2024-12-04 17:07:49</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.801045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662753</td>\n",
       "      <td>0.506805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528222</td>\n",
       "      <td>0.510606</td>\n",
       "      <td>0.569024</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attn_span_1536</th>\n",
       "      <td>2024-12-04 17:08:04</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.690310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.330619</td>\n",
       "      <td>0.495117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471778</td>\n",
       "      <td>0.510606</td>\n",
       "      <td>0.569024</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attn_span_2048</th>\n",
       "      <td>2024-12-04 17:08:19</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.690707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664962</td>\n",
       "      <td>0.495117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535964</td>\n",
       "      <td>0.509848</td>\n",
       "      <td>0.561869</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attn_span_4096</th>\n",
       "      <td>2024-12-04 17:08:34</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.690707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.330619</td>\n",
       "      <td>0.506805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520480</td>\n",
       "      <td>0.491414</td>\n",
       "      <td>0.554714</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_2e-3</th>\n",
       "      <td>2024-12-04 18:15:21</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.691502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>added_loss</th>\n",
       "      <td>2024-12-04 19:28:46</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.691188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664911</td>\n",
       "      <td>0.505284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469411</td>\n",
       "      <td>0.505580</td>\n",
       "      <td>0.565476</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_2e-5</th>\n",
       "      <td>2024-12-04 19:29:50</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.692484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664851</td>\n",
       "      <td>0.505713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473049</td>\n",
       "      <td>0.505580</td>\n",
       "      <td>0.565476</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_2e-4</th>\n",
       "      <td>2024-12-04 19:30:49</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.691188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664851</td>\n",
       "      <td>0.505427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.474868</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.639881</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ramp_64</th>\n",
       "      <td>2024-12-04 19:31:43</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.689244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664911</td>\n",
       "      <td>0.505427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473049</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.528274</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ramp_16</th>\n",
       "      <td>2024-12-04 19:32:57</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.689892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664851</td>\n",
       "      <td>0.505284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471230</td>\n",
       "      <td>0.512277</td>\n",
       "      <td>0.528274</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_0.5</th>\n",
       "      <td>2024-12-04 19:34:20</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.818481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.855843</td>\n",
       "      <td>0.900402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645337</td>\n",
       "      <td>0.909598</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_1</th>\n",
       "      <td>2024-12-04 19:35:19</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.813098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.856761</td>\n",
       "      <td>0.898249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660880</td>\n",
       "      <td>0.916295</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_5</th>\n",
       "      <td>2024-12-04 19:36:13</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.808363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.843331</td>\n",
       "      <td>0.890828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.915179</td>\n",
       "      <td>0.459821</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_10</th>\n",
       "      <td>2024-12-04 19:37:07</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.801087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835928</td>\n",
       "      <td>0.900958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624339</td>\n",
       "      <td>0.907366</td>\n",
       "      <td>0.491071</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attn_span_1536</th>\n",
       "      <td>2024-12-04 19:38:01</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.691836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664851</td>\n",
       "      <td>0.505284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469411</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.528274</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attn_span_2048</th>\n",
       "      <td>2024-12-04 19:38:56</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.693780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.665030</td>\n",
       "      <td>0.505427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473049</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.434524</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attn_span_4096</th>\n",
       "      <td>2024-12-04 19:39:56</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.692484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664791</td>\n",
       "      <td>0.505713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473049</td>\n",
       "      <td>0.512277</td>\n",
       "      <td>0.528274</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_2e-3</th>\n",
       "      <td>2024-12-04 20:50:39</td>\n",
       "      <td>octal40</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.691188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664611</td>\n",
       "      <td>0.504998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476687</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.639881</td>\n",
       "      <td>/Tmp/lvpoellhuber/models/finetune_roberta/adap...</td>\n",
       "      <td>{'settings': {'model': 'FacebookAI/roberta-bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               date computer  job_id      cola      mnli  \\\n",
       "roberta_test    2024-12-04 16:33:02  octal40    1433  0.696389       NaN   \n",
       "sparse_ft       2024-12-04 16:37:23  octal40    1435  0.637677  0.316863   \n",
       "added_loss      2024-12-04 16:38:17  octal40    1436  0.693487       NaN   \n",
       "sparse_ft       2024-12-04 17:05:29  octal40    1438  0.638869  0.381189   \n",
       "added_loss      2024-12-04 17:05:48  octal40    1439  0.691502       NaN   \n",
       "loss_2e-5       2024-12-04 17:06:03  octal40    1439  0.691502       NaN   \n",
       "loss_2e-4       2024-12-04 17:06:18  octal40    1439  0.692296       NaN   \n",
       "ramp_64         2024-12-04 17:06:33  octal40    1439  0.689913       NaN   \n",
       "ramp_16         2024-12-04 17:06:49  octal40    1439  0.689913       NaN   \n",
       "init_0.5        2024-12-04 17:07:04  octal40    1439  0.815952       NaN   \n",
       "init_1          2024-12-04 17:07:19  octal40    1439  0.812408       NaN   \n",
       "init_5          2024-12-04 17:07:34  octal40    1439  0.808071       NaN   \n",
       "init_10         2024-12-04 17:07:49  octal40    1439  0.801045       NaN   \n",
       "attn_span_1536  2024-12-04 17:08:04  octal40    1439  0.690310       NaN   \n",
       "attn_span_2048  2024-12-04 17:08:19  octal40    1439  0.690707       NaN   \n",
       "attn_span_4096  2024-12-04 17:08:34  octal40    1439  0.690707       NaN   \n",
       "loss_2e-3       2024-12-04 18:15:21  octal40    1439  0.691502       NaN   \n",
       "added_loss      2024-12-04 19:28:46  octal40    1446  0.691188       NaN   \n",
       "loss_2e-5       2024-12-04 19:29:50  octal40    1446  0.692484       NaN   \n",
       "loss_2e-4       2024-12-04 19:30:49  octal40    1446  0.691188       NaN   \n",
       "ramp_64         2024-12-04 19:31:43  octal40    1446  0.689244       NaN   \n",
       "ramp_16         2024-12-04 19:32:57  octal40    1446  0.689892       NaN   \n",
       "init_0.5        2024-12-04 19:34:20  octal40    1446  0.818481       NaN   \n",
       "init_1          2024-12-04 19:35:19  octal40    1446  0.813098       NaN   \n",
       "init_5          2024-12-04 19:36:13  octal40    1446  0.808363       NaN   \n",
       "init_10         2024-12-04 19:37:07  octal40    1446  0.801087       NaN   \n",
       "attn_span_1536  2024-12-04 19:38:01  octal40    1446  0.691836       NaN   \n",
       "attn_span_2048  2024-12-04 19:38:56  octal40    1446  0.693780       NaN   \n",
       "attn_span_4096  2024-12-04 19:39:56  octal40    1446  0.692484       NaN   \n",
       "loss_2e-3       2024-12-04 20:50:39  octal40    1446  0.691188       NaN   \n",
       "\n",
       "                    mrpc      qnli       qqp       rte      sst2      wnli  \\\n",
       "roberta_test    0.722285  0.533351       NaN  0.479520  0.490909  0.423822   \n",
       "sparse_ft       0.589015  0.544883  0.368183  0.507992  0.498737  0.561869   \n",
       "added_loss      0.662753  0.506805       NaN  0.456294  0.509848  0.569024   \n",
       "sparse_ft       0.595644  0.544883  0.633111  0.484765  0.498737  0.540404   \n",
       "added_loss      0.662753  0.506805       NaN  0.456294  0.509848  0.569024   \n",
       "loss_2e-5       0.662753  0.503922       NaN  0.471778  0.508838  0.576178   \n",
       "loss_2e-4       0.662753  0.506805       NaN  0.471778  0.509343  0.540404   \n",
       "ramp_64         0.664962  0.504883       NaN  0.440809  0.507828  0.576178   \n",
       "ramp_16         0.667172  0.504883       NaN  0.479520  0.510354  0.561869   \n",
       "init_0.5        0.856313  0.900909       NaN  0.632118  0.907449  0.203283   \n",
       "init_1          0.855240  0.896987       NaN  0.625125  0.920581  0.554714   \n",
       "init_5          0.667172  0.495117       NaN  0.528222  0.510354  0.423822   \n",
       "init_10         0.662753  0.506805       NaN  0.528222  0.510606  0.569024   \n",
       "attn_span_1536  0.330619  0.495117       NaN  0.471778  0.510606  0.569024   \n",
       "attn_span_2048  0.664962  0.495117       NaN  0.535964  0.509848  0.561869   \n",
       "attn_span_4096  0.330619  0.506805       NaN  0.520480  0.491414  0.554714   \n",
       "loss_2e-3            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "added_loss      0.664911  0.505284       NaN  0.469411  0.505580  0.565476   \n",
       "loss_2e-5       0.664851  0.505713       NaN  0.473049  0.505580  0.565476   \n",
       "loss_2e-4       0.664851  0.505427       NaN  0.474868  0.508929  0.639881   \n",
       "ramp_64         0.664911  0.505427       NaN  0.473049  0.515625  0.528274   \n",
       "ramp_16         0.664851  0.505284       NaN  0.471230  0.512277  0.528274   \n",
       "init_0.5        0.855843  0.900402       NaN  0.645337  0.909598  0.166667   \n",
       "init_1          0.856761  0.898249       NaN  0.660880  0.916295  0.677083   \n",
       "init_5          0.843331  0.890828       NaN  0.678571  0.915179  0.459821   \n",
       "init_10         0.835928  0.900958       NaN  0.624339  0.907366  0.491071   \n",
       "attn_span_1536  0.664851  0.505284       NaN  0.469411  0.508929  0.528274   \n",
       "attn_span_2048  0.665030  0.505427       NaN  0.473049  0.508929  0.434524   \n",
       "attn_span_4096  0.664791  0.505713       NaN  0.473049  0.512277  0.528274   \n",
       "loss_2e-3       0.664611  0.504998       NaN  0.476687  0.515625  0.639881   \n",
       "\n",
       "                                                       model_path  \\\n",
       "roberta_test    /Tmp/lvpoellhuber/models/finetune_roberta/robe...   \n",
       "sparse_ft       /Tmp/lvpoellhuber/models/finetune_roberta/spar...   \n",
       "added_loss      /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "sparse_ft       /Tmp/lvpoellhuber/models/finetune_roberta/spar...   \n",
       "added_loss      /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "loss_2e-5       /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "loss_2e-4       /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "ramp_64         /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "ramp_16         /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "init_0.5        /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "init_1          /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "init_5          /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "init_10         /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "attn_span_1536  /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "attn_span_2048  /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "attn_span_4096  /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "loss_2e-3       /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "added_loss      /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "loss_2e-5       /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "loss_2e-4       /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "ramp_64         /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "ramp_16         /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "init_0.5        /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "init_1          /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "init_5          /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "init_10         /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "attn_span_1536  /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "attn_span_2048  /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "attn_span_4096  /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "loss_2e-3       /Tmp/lvpoellhuber/models/finetune_roberta/adap...   \n",
       "\n",
       "                                                           config  \n",
       "roberta_test    {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "sparse_ft       {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "added_loss      {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "sparse_ft       {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "added_loss      {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "loss_2e-5       {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "loss_2e-4       {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "ramp_64         {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "ramp_16         {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "init_0.5        {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "init_1          {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "init_5          {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "init_10         {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "attn_span_1536  {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "attn_span_2048  {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "attn_span_4096  {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "loss_2e-3       {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "added_loss      {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "loss_2e-5       {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "loss_2e-4       {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "ramp_64         {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "ramp_16         {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "init_0.5        {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "init_1          {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "init_5          {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "init_10         {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "attn_span_1536  {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "attn_span_2048  {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "attn_span_4096  {'settings': {'model': 'FacebookAI/roberta-bas...  \n",
       "loss_2e-3       {'settings': {'model': 'FacebookAI/roberta-bas...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_df = pd.read_csv(os.path.join(STORAGE_DIR, \"experiment_df.csv\"), index_col=0)\n",
    "experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmir-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
