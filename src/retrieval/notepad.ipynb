{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Tmp/lvpoellhuber/bmir-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: Using incubator modules: jdk.incubator.vector\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoModel, DPRQuestionEncoder\n",
    "from datasets import load_dataset\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir import util\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from torchviz import make_dot\n",
    "from losses import contrastive_loss\n",
    "\n",
    "from model_biencoder import BiEncoder\n",
    "from preprocessing import get_triplets_dataloader, get_pairs_dataloader\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib64/openjdk-21\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Comparisons\n",
    "\n",
    "Comparing E5's automatic implementation and mine's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "custom_model = BiEncoder(model_path = (\"intfloat/e5-base-v2\", \"intfloat/e5-base-v2\"), sep=\" [SEP] \")\n",
    "custom_q_model = custom_model.q_model.to(\"cpu\")\n",
    "base_model = AutoModel.from_pretrained(\"intfloat/e5-base-v2\").to(\"cpu\")\n",
    "\n",
    "# Compare weights\n",
    "custom_weights = custom_q_model.state_dict().keys()\n",
    "\n",
    "for name, param in base_model.named_parameters():\n",
    "    #print(name)\n",
    "    if name in custom_weights:\n",
    "        custom_param = custom_q_model.state_dict()[name]\n",
    "        if torch.equal(param, custom_param):\n",
    "            #print(f\"Layer {name} matches\")\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Layer {name} does not match\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Layer {name} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing DPR's implementation with mine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "custom_model = BiEncoder(model_path = (\"facebook/dpr-question_encoder-single-nq-base\", \"facebook/dpr-ctx_encoder-single-nq-base\"), sep=\" [SEP] \")\n",
    "custom_q_model = custom_model.q_model.to(\"cpu\")\n",
    "base_model = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\").to(\"cpu\")\n",
    "\n",
    "# Compare weights\n",
    "custom_weights = custom_q_model.state_dict().keys()\n",
    "\n",
    "for name, param in base_model.named_parameters():\n",
    "    #print(name)\n",
    "    if name in custom_weights:\n",
    "        custom_param = custom_q_model.state_dict()[name]\n",
    "        if torch.equal(param, custom_param):\n",
    "            #print(f\"Layer {name} matches\")\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Layer {name} does not match\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Layer {name} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr_model = BiEncoder(\n",
    "    model_path=(\"google-bert/bert-base-uncased\", \"google-bert/bert-base-uncased\"),\n",
    "    normalize=False,\n",
    "    prompts={\"query\": \"\", \"passage\": \"\"},\n",
    "    attn_implementation=\"eager\", \n",
    "    sep = \" [SEP] \", \n",
    "    batch_size=batch_size\n",
    ")\n",
    "dpr_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(\"/Tmp/lvpoellhuber/datasets/nq\", \"train_triplets.pt\")\n",
    "dataloader = get_triplets_dataloader(batch_size=batch_size, dataset_path=dataset_path,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(\"/Tmp/lvpoellhuber/datasets/nq\", \"train_pairs.pt\")\n",
    "dataloader = get_pairs_dataloader(batch_size=batch_size, dataset_path=dataset_path,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr_params = {}\n",
    "\n",
    "q_params = dict(dpr_model.q_model.named_parameters())\n",
    "doc_params = dict(dpr_model.doc_model.named_parameters())\n",
    "for param in q_params.keys():\n",
    "    q_param = q_params[param]\n",
    "    doc_param = doc_params[param]\n",
    "\n",
    "    dpr_params[\"q_encoder.\"+param] = q_param \n",
    "    dpr_params[\"doc_encoder.\"+param] = doc_param "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [item for item in dataloader][0]\n",
    "\n",
    "queries = batch[\"queries\"]\n",
    "# documents = batch[\"documents\"]\n",
    "positives = batch[\"positives\"]\n",
    "negatives = batch[\"negatives\"]\n",
    "documents = positives + negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpr_step(queries, documents):\n",
    "    q_embeddings = dpr_model.encode_queries(queries, convert_to_tensor=True) # All three 16x512\n",
    "    doc_embeddings = dpr_model.encode_corpus(documents, convert_to_tensor=True) # All three 16x512\n",
    "\n",
    "    loss = contrastive_loss(q_embeddings, doc_embeddings)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# loss = dpr_step(queries, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/u/poellhul/Documents/Masters/benchmarkIR-slurm/src/retrieval/dual_graph.pdf'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(dpr_step(queries, documents), params=dpr_params, show_attrs=True).render(\"/u/poellhul/Documents/Masters/benchmarkIR-slurm/src/retrieval/dual_graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/u/poellhul/Documents/Masters/benchmarkIR-slurm/src/retrieval/doc_graph.pdf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(dpr_model.encode_corpus(documents, convert_to_tensor=True), params=dpr_params, show_attrs=True).render(\"/u/poellhul/Documents/Masters/benchmarkIR-slurm/src/retrieval/doc_graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(\"/Tmp/lvpoellhuber/datasets/nq/train_pairs.pt\")\n",
    "dataloader = get_pairs_dataloader(batch_size=12, dataset_path=dataset_path)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Tmp/lvpoellhuber/bmir-env/lib/python3.12/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Tmp/lvpoellhuber/bmir-env/lib/python3.12/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Tmp/lvpoellhuber/bmir-env/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m/Tmp/lvpoellhuber/bmir-env/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(\"huh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11067"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmir-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
